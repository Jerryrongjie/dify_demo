app:
  description: 'It''s a simple demo of chatflow to simulating o1 CoT(Chain of Thought)
    mode.


    Provided by: Jerry Ye'
  icon: 🤖
  icon_background: '#FFEAD5'
  mode: advanced-chat
  name: CoT Chatflow
  use_icon_as_answer_icon: false
kind: app
version: 0.1.4
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_size_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: ''
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        sourceType: start
        targetType: llm
      id: 1734854371599-llm
      source: '1734854371599'
      sourceHandle: source
      target: llm
      targetHandle: target
      type: custom
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: llm-source-1734854639225-target
      source: llm
      sourceHandle: source
      target: '1734854639225'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: parameter-extractor
      id: 1734854639225-source-1734856853467-target
      source: '1734854639225'
      sourceHandle: source
      target: '1734856853467'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: parameter-extractor
        targetType: iteration
      id: 1734856853467-source-1734856942559-target
      source: '1734856853467'
      sourceHandle: source
      target: '1734856942559'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: iteration
        targetType: template-transform
      id: 1734856942559-source-1734882559796-target
      source: '1734856942559'
      sourceHandle: source
      target: '1734882559796'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: template-transform
        targetType: llm
      id: 1734882559796-source-1734882776733-target
      source: '1734882559796'
      sourceHandle: source
      target: '1734882776733'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1734882776733-source-1734883088635-target
      source: '1734882776733'
      sourceHandle: source
      target: '1734883088635'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: true
        iteration_id: '1734856942559'
        sourceType: iteration-start
        targetType: llm
      id: 1734856942559start-source-1734881294884-target
      source: 1734856942559start
      sourceHandle: source
      target: '1734881294884'
      targetHandle: target
      type: custom
      zIndex: 1002
    nodes:
    - data:
        desc: ''
        selected: false
        title: 开始
        type: start
        variables: []
      height: 54
      id: '1734854371599'
      position:
        x: 30
        y: 301.5
      positionAbsolute:
        x: 30
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - sys
          - query
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 50
        model:
          completion_params:
            max_tokens: 4095
            num_predict: 127998
            temperature: 0.6
          mode: chat
          name: qwen2.5:14b
          provider: ollama
        prompt_template:
        - edition_type: basic
          id: 39d9f67a-bd9a-4802-8171-0d402066c93b
          role: system
          text: '你是一个能够详细分析用户问题、拆解任务步骤、按步骤逐步完成任务的智能助手。

            对于每一次与用户的互动，你在回答前必须进行全面的、自然的思考过程。


            # 要求

            当你第一次接受用户的信息时，你应该这样做：

            1. 首先获取用户提问{{#sys.query#}}

            2. 用自然语言清楚地重新表述人类的信息

            3 对被问到的问题形成初步印象

            4. 考虑一下这个问题的大背景

            5. 标出已知和未知的元素

            6. 想想为什么人类会问这个问题

            7. 找出与相关知识的直接联系

            8. 识别任何需要澄清的潜在含糊之处


            # 任务

            请根据"要求"完成问题分析。


            # 限制

            请不要尝试直接解答问题。'
        selected: false
        title: 问题分析
        type: llm
        variables: []
        vision:
          configs:
            detail: high
            variable_selector:
            - sys
            - files
          enabled: false
      height: 98
      id: llm
      position:
        x: 334
        y: 301.5
      positionAbsolute:
        x: 334
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - llm
          - text
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 50
        model:
          completion_params:
            format: json
            max_tokens: 4095
            num_ctx: 128000
            temperature: 0.6
          mode: chat
          name: glm-4-flash
          provider: zhipuai
        prompt_template:
        - id: 6f9b66de-e7cf-4f12-9383-50154bc7343a
          role: system
          text: "你是一个能够详细分析用户问题、拆解任务步骤、按步骤逐步完成任务的智能助手。\n对于每一次与用户的互动，你在回答前必须进行全面的、自然的思考过程。\n\
            \n# 要求\n你已完成的问题的分析，接下来请根据分析结果和用户的原始问题进行任务拆解：\n1. 获取上一轮的分析结果\"{{#llm.text#}}\"\
            和用户的原始提问\"{{#sys.query#}}\"。\n2. 识别明确的和隐含的需求\n3. 考虑任何约束或限制\n4. 想想一个成功的回应应该是什么样的\n\
            5. 绘制出解决问题所需的知识范围\n\n# 任务\n1. 根据\"要求\"完成任务步骤拆解。\n2. 模仿<example></example>标签内的案例生成问题的解决步骤并说明该任务要求。\n\
            3. 按照json格式返回任务步骤数组。\n\n<example>\n[ \n\t{ \n\t\t\"name\": \"步骤名称\", \n\
            \t\t\"content\": \"任务描述\" \n\t}, \n\t{\n\t\t\"name\"：\"步骤名称\", \n\t\t\"\
            content\"：\"任务描述\"\n\t}, \n\t... \n]\n</example>\n\n# 限制\n1. 请不要试图自行解答问题。\n\
            2. 请务必使用json格式返回任务步骤，否则你就失败了。\n3. 请不要使用 ```json 包裹内容。\n"
        selected: false
        title: 任务拆解
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1734854639225'
      position:
        x: 638
        y: 301.5
      positionAbsolute:
        x: 638
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        instruction: "提取内容中的任务步骤数组，示例如下： \n[ \n\t{ \n\t\t\"name\": \"步骤名称\", \n\t\t\
          \"content\": \"任务描述\" \n\t}, \n\t{\n\t\t\"name\"：\"步骤名称\", \n\t\t\"content\"\
          ：\"任务描述\"\n\t}, \n\t... \n]"
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen2.5:14b
          provider: ollama
        parameters:
        - description: 需要执行的任务数组对象
          name: tasks
          required: false
          type: array[object]
        query:
        - '1734854639225'
        - text
        reasoning_mode: prompt
        selected: false
        title: 参数转换为 Array
        type: parameter-extractor
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1734856853467'
      position:
        x: 942
        y: 301.5
      positionAbsolute:
        x: 942
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        error_handle_mode: terminated
        height: 203
        is_parallel: false
        iterator_selector:
        - '1734856853467'
        - tasks
        output_selector:
        - '1734881294884'
        - text
        output_type: array[string]
        parallel_nums: 10
        selected: false
        start_node_id: 1734856942559start
        title: 迭代
        type: iteration
        width: 423
      height: 203
      id: '1734856942559'
      position:
        x: 1246
        y: 301.5
      positionAbsolute:
        x: 1246
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 423
      zIndex: 1
    - data:
        desc: ''
        isInIteration: true
        selected: false
        title: ''
        type: iteration-start
      draggable: false
      height: 48
      id: 1734856942559start
      parentId: '1734856942559'
      position:
        x: 24
        y: 68
      positionAbsolute:
        x: 1270
        y: 369.5
      selectable: false
      sourcePosition: right
      targetPosition: left
      type: custom-iteration-start
      width: 44
      zIndex: 1002
    - data:
        context:
          enabled: true
          variable_selector:
          - '1734856942559'
          - item
        desc: ''
        isInIteration: true
        iteration_id: '1734856942559'
        model:
          completion_params:
            max_tokens: 4095
            num_ctx: 12800
            temperature: 0.6
          mode: chat
          name: qwen2.5:14b
          provider: ollama
        prompt_template:
        - id: 5fd91038-7506-471a-9a16-7c6dda84a1e5
          role: system
          text: '你是一个能够详细分析用户问题、拆解任务步骤、按步骤逐步完成任务的智能助手。

            对于每一次与用户的互动，你在回答前必须进行全面的、自然的思考过程。


            # 要求

            你已完成任务的规划，请根据当前获取的任务名称、描述完成任务：

            1. 从上下文```{{#1734856942559.item#}}```获取你的任务名称"name"​和描述"context"

            2. 写出对这个任务的多种可能的解释

            3. 考虑各种解决方案

            4. 回顾各种解决方案的可行性

            5. 按照下面的格式要求完成任务解答：

            **任务名称**

            描述：


            解答：

            ============================


            # 任务

            1. 直接说明任务的名称、描述。

            2. 根据"要求"对任务进行解答。

            3. 请再次检查内容是否符合格式要求，在有需要时对内容格式进行进一步调整。


            # 案例

            <example>

            **任务：手动计数**


            描述：

            遍历单词 ''strawberry'' 的每个字母，统计字母 ''r'' 出现的次数。


            解答：

            通过手动遍历单词 ''strawberry''，我们可以逐个字母进行检查和计数。具体步骤如下：

            1. 从单词的第一个字母开始，依次查看每个字母。

            2. 每当遇到字母 ''r'' 时，计数器加1。

            3. 继续遍历直到单词的最后一个字母。


            经过手动计数，字母 ''r'' 在单词 ''strawberry'' 中出现了 3 次。

            ============================


            </example>


            # 限制

            1. 不必输出任何解释，直接完成任务的回答。

            2. 请务必使用Markdown格式回答问题，否则你就失败了。

            3. 不要输出 <example></example>标签。

            '
        selected: false
        title: 任务执行
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1734881294884'
      parentId: '1734856942559'
      position:
        x: 159.64203805449824
        y: 65
      positionAbsolute:
        x: 1405.6420380544982
        y: 366.5
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1002
    - data:
        desc: ''
        selected: false
        template: '{{ answers | join("\n\n")}}'
        title: 任务执行整合
        type: template-transform
        variables:
        - value_selector:
          - '1734856942559'
          - output
          variable: answers
      height: 54
      id: '1734882559796'
      position:
        x: 1727.5714285714287
        y: 301.5
      positionAbsolute:
        x: 1727.5714285714287
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1734882559796'
          - output
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: false
            size: 50
        model:
          completion_params:
            max_tokens: 4095
            num_ctx: 12800
            temperature: 0.6
          mode: chat
          name: glm-4-plus
          provider: zhipuai
        prompt_template:
        - id: 88efcfcb-46ba-4866-8b6f-9258b45062e6
          role: system
          text: '你是一个能够详细分析用户问题、拆解任务步骤、按步骤逐步完成任务的智能助手。

            对于每一次与用户的互动，你在回答前必须进行全面的、自然的思考过程。


            # 要求

            你已完成所有任务的解答，请根据下面要求进行内容整合并输出结论：

            1. 检查原始问题"{{#sys.query#}}"并归纳所有分析过程。

            - 初步分析: {{#llm.text#}}

            - 任务拆解: {{#1734854639225.text#}}

            - 任务执行: {{#1734882559796.output#}}

            2. 根据以获取的信息，按**步骤**对问题进行总结并输出结论。

            3. 使用Markdown格式输出内容，提高可读性。

            4. 深呼吸，再次回顾一下你输出的推理过程是否逻辑清晰。


            # 任务

            1. 根据"要求"完成结论的输出

            2. 按照下面的内容结构进行问题总结归纳：

            ## 问题分析

            ...


            ## 任务拆解与执行

            ...


            ## 结论

            ...



            # 案例

            模仿<example></example>标签内的格式要求进行回答

            <example>

            ## 问题分析

            {{#llm.text#}}


            ## 任务拆解与执行

            {{#1734882559796.output#}}


            ## 结论

            ...


            </example>


            # 限制

            1. 请严格按照<example></example>内的格式输出内容，否则你就失败了。'
        selected: false
        title: 输出结论
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1734882776733'
      position:
        x: 2033
        y: 301.5
      positionAbsolute:
        x: 2033
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: "    \n{{#1734882776733.text#}}"
        desc: ''
        selected: false
        title: 问题结论
        type: answer
        variables: []
      height: 102
      id: '1734883088635'
      position:
        x: 2337
        y: 301.5
      positionAbsolute:
        x: 2337
        y: 301.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: 102.70000000000044
      y: 138.75
      zoom: 0.7
